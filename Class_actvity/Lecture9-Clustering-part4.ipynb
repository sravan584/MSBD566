{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dad0dc6",
   "metadata": {},
   "source": [
    "# MSBD 566 - Lecture 9\n",
    "## Clustering - Work with Real Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ef38cb",
   "metadata": {},
   "source": [
    "### The data [from Data Science and Predictive Analytics by Ivo D. Dinov]\n",
    "\n",
    "The dataset we will be using is the Divorce and Consequences on Young Adults dataset. This is a longitudinal study focused on examining the consequences of recent parental divorce for young adults (initially ages 18–23) whose parents had divorced within 15 months of the study’s rst wave (1990–91). The sample consisted of 257 White respondents with newly divorced parents. Here we have a subset of this dataset with 47 respondents in our case-studies folder, CaseStudy01_Divorce_YoungAdults_Data.csv.\n",
    "\n",
    "**Variables**\n",
    "* `DIVYEAR`: Year in which parents were divorced. Dichotomous variable with\n",
    "1989 and 1990.\n",
    "* Child affective relations:\n",
    "  * `Momint`: Mother intimacy. Interval level data with four possible responses (1-extremely close, 2-quite close, 3-fairly close, 4- not close at all).\n",
    "  * `Dadint`: Father intimacy. Interval level data with four possible responses (1-extremely close, 2-quite close, 3-fairly close, 4-not close at all).\n",
    "  * `Live with mom`: Polytomous variable with three categories (1- mother only, 2-father only, 3- both parents).\n",
    "* `momclose`: measure of how close the child is to the mother (1-extremely close, 2-quite close, 3-fairly close, 4-not close at all).\n",
    "* `Depression`: Interval level data regarding feelings of depression in the past 4 weeks. Possible responses are 1-often, 2-sometimes, 3-hardly ever, 4-never.\n",
    "* `Gethitched`: Polytomous variable with four possible categories indicating respondent’s plan for marriage (1-Marry fairly soon, 2-marry sometime, 3-never marry, 8-don’t know)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5299c4",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded02aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de79b312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "data = pd.read_csv('CaseStudy01_Divorce_YoungAdults_Data.csv')\n",
    "print(data.head())\n",
    "print(f\"Data shape (before cleaning): {data.shape}\")\n",
    "\n",
    "# clear missing value\n",
    "data = data.dropna()\n",
    "print(f\"Data shape (after cleaning): {data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c07ceab",
   "metadata": {},
   "source": [
    "We have to make sure all the values are valid as described above. \n",
    "\n",
    "For example:\n",
    "* According to the summary, DIVYEAR is actually a dummy variable (either 89 or 90). So we can probably change them to binary (0 for 1989 and 1 for 1990)\n",
    "* There is 9 for `livewithmom` which is not a valid number for this variable. We have options to remove this row, or change to something that makes more sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1aef07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check general statistics - to see any anomalies\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b952456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change DIVYEAR to binary\n",
    "data['DIVYEAR'] = data['DIVYEAR'].replace({89: 0, 90: 1})\n",
    "print(data['DIVYEAR'].value_counts()) # just to double check\n",
    "\n",
    "# change livewithmom = 9 to NaN and drop\n",
    "data['livewithmom'] = data['livewithmom'].replace(9, np.nan)\n",
    "data = data.dropna()\n",
    "print(f\"Data shape (after cleaning livewithmom): {data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30eb1935",
   "metadata": {},
   "source": [
    "### Clustering Method 1: k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb9b340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means clustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "# Determine the optimal number of clusters using the silhoutte score method\n",
    "\n",
    "silhouette_scores = []\n",
    "k_range = np.arange(2, 10)\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(data_scaled)\n",
    "    silhouette_avg = silhouette_score(data_scaled, cluster_labels)\n",
    "    silhouette_scores.append(silhouette_avg)\n",
    "\n",
    "# Plotting the silhouette scores\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.plot(k_range, silhouette_scores, marker='o')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Score Method for Optimal k')\n",
    "plt.show()\n",
    "\n",
    "# Choosing k based on the silhouette plot\n",
    "optimalK = k_range[np.argmax(silhouette_scores)]\n",
    "print(f\"The optimal number of clusters (k) is: {optimalK}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c77264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running K-means\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "data['Cluster_kmeans'] = kmeans.fit_predict(data_scaled)\n",
    "print(data.head())\n",
    "\n",
    "print(\"Cluster counts:\")\n",
    "print(data['Cluster_kmeans'].value_counts())\n",
    "\n",
    "# Visualizing clusters on plots based on two features - live with mom vs close to mom\n",
    "plt.figure(figsize=(6, 3))\n",
    "markerlist = ['o', 's', 'D', 'X', 'P']\n",
    "# each cluster will have different shapes and colors\n",
    "sns.scatterplot(x=data.columns[5], y=data.columns[1], hue='Cluster_kmeans', data=data, palette='Set1', markers=markerlist[:len(data['Cluster_kmeans'].unique())], style='Cluster_kmeans')\n",
    "plt.title('K-means Clustering Results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a195ca99",
   "metadata": {},
   "source": [
    "### Clustering Method 2: DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d007848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using DBSCAN for clustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "# calculate eps for dbscan\n",
    "bandwidth = estimate_bandwidth(data_scaled, quantile=0.2, n_samples=45)\n",
    "print(f\"Estimated bandwidth (eps) for DBSCAN: {bandwidth}\")\n",
    "\n",
    "# running DBSCAN\n",
    "dbscan = DBSCAN(eps=bandwidth, min_samples=5)  # eps and min_samples need to be tuned\n",
    "data['Cluster_dbscan'] = dbscan.fit_predict(data_scaled)\n",
    "print(data.head())\n",
    "\n",
    "print(\"Cluster counts:\")\n",
    "print(data['Cluster_dbscan'].value_counts())\n",
    "\n",
    "# Visualizing DBSCAN clusters on plots based on two features - live with mom vs close to mom\n",
    "markerlist = ['o', 's', 'D', 'X', 'P']\n",
    "plt.figure(figsize=(6, 3))\n",
    "# each cluster will have different shapes and colors\n",
    "sns.scatterplot(x=data.columns[5], y=data.columns[1], hue='Cluster_dbscan', data=data, palette='Set1', markers=markerlist[:len(data['Cluster_dbscan'].unique())], style='Cluster_dbscan')\n",
    "plt.title('DBSCAN Clustering Results')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20d37b9",
   "metadata": {},
   "source": [
    "### Clustering Method 3: Mean-Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de36e5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean shift clustering\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "# Estimate bandwidth\n",
    "bandwidth = estimate_bandwidth(data_scaled, quantile=0.2)\n",
    "print(f\"Estimated bandwidth: {bandwidth}\")\n",
    "\n",
    "# running Mean Shift\n",
    "mean_shift = MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "data['Cluster_meanshift'] = mean_shift.fit_predict(data_scaled)\n",
    "print(data.head())\n",
    "\n",
    "print(\"Cluster counts:\")\n",
    "print(data['Cluster_meanshift'].value_counts())\n",
    "\n",
    "# Visualizing Mean Shift clusters on plots based on two features - live with mom vs close to mom\n",
    "markerlist = ['o', 's', 'D', 'X', 'P']\n",
    "plt.figure(figsize=(6, 3))\n",
    "# each cluster will have different shapes and colors\n",
    "sns.scatterplot(x=data.columns[5], y=data.columns[1], hue='Cluster_meanshift', data=data, palette='Set1', markers=markerlist[:len(data['Cluster_meanshift'].unique())], style='Cluster_meanshift')\n",
    "plt.title('Mean Shift Clustering Results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff4bc96",
   "metadata": {},
   "source": [
    "### Comparing the methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857ae8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the methods\n",
    "print(\"Cluster counts:\")\n",
    "print(data[['Cluster_kmeans', 'Cluster_dbscan', 'Cluster_meanshift']].nunique())\n",
    "\n",
    "# set the dataframe to compare each method \n",
    "df = {'Kmeans': data['Cluster_kmeans'],\n",
    "      'DBSCAN': data['Cluster_dbscan'],\n",
    "      'MeanShift': data['Cluster_meanshift']}\n",
    "\n",
    "# cross tab\n",
    "ctab = pd.crosstab(df['DBSCAN'], df['MeanShift'])\n",
    "print(ctab)\n",
    "\n",
    "# Create heatmap to compare clustering results\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(ctab, annot=True, square=True, fmt='d')\n",
    "plt.title(\"Cluster Cross-Tabulation (Kmeans vs DBSCAN)\")\n",
    "plt.xlabel(\"DBSCAN Clusters\")\n",
    "plt.ylabel(\"MeanShift Clusters\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
